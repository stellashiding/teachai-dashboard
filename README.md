# ðŸ§  TEACH-AI Dashboard (Prototype)

The **TEACH-AI Dashboard** is an open-source prototype to evaluate generative AI tutors using the **TEACH-AI Benchmark Framework**.  
It helps researchers and educators assess models across **10 educational dimensions** â€” from Explainability and Helpfulness to Accessibility and Ethics â€” using an **LLM-as-Judge** approach.

---

## ðŸš€ Features
- Evaluate AI tutor responses using standardized scoring (1â€“5)  
- Includes 10 TEACH-AI components with prompt-based questions  
- Built in **Python + Flask** with a simple evaluation UI  
- Designed for future dashboard visualization and open collaboration  

---

## ðŸ“Š Example Use
Example evaluation task (EarSketch / Deeproject context):

> **Prompt:** â€œHow can you make your music composition in EarSketch more expressive using code?â€
>
> **Model Responses:**  
> GPT-4: â€œUse automation to gradually increase volume and add echo for emotional effect.â€  
> Claude-3: â€œTry combining rhythm variation and panning to make transitions feel more human.â€  
> Gemini-1.5: â€œLayer multiple instrument tracks and change effects dynamically with loops.â€

Each response is scored automatically across the TEACH-AI dimensions.

---

## ðŸ§  Citation
If you use or reference this work, please cite:
> Ding, S. (2025). *The TEACH-AI Benchmark*

---

## ðŸªª License
MIT License Â© 2025  
Part of ongoing research at Georgia Techâ€™s Expressive Machinery Lab.
